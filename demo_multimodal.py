"""
Multimodal Text Generation Demo
ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆ â†’ ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã®ãƒ‡ãƒ¢
"""
import requests
import json
import numpy as np
from PIL import Image
import io
import base64
from typing import Dict, Any

def create_demo_image() -> bytes:
    """ãƒ‡ãƒ¢ç”¨ã®ç”»åƒã‚’ç”Ÿæˆ"""
    # ç°¡å˜ãªè‰²ä»˜ãã®ç”»åƒã‚’ä½œæˆ
    image = Image.new('RGB', (224, 224), color='lightblue')
    
    # ä¸­å¤®ã«å››è§’å½¢ã‚’æç”»
    from PIL import ImageDraw
    draw = ImageDraw.Draw(image)
    draw.rectangle([50, 50, 174, 174], fill='red', outline='black', width=2)
    draw.text((80, 100), "DEMO", fill='white')
    
    # ãƒã‚¤ãƒˆã«å¤‰æ›
    img_buffer = io.BytesIO()
    image.save(img_buffer, format='JPEG')
    return img_buffer.getvalue()

class MultimodalDemo:
    """ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
    
    def check_server_status(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã‚’ç¢ºèª"""
        try:
            response = requests.get(f"{self.base_url}/")
            return response.json()
        except Exception as e:
            return {"error": str(e), "status": "server_unavailable"}
    
    def test_multimodal_inference(self, 
                                image_bytes: bytes,
                                text_prompt: str,
                                model_name: str = "demo_model") -> Dict[str, Any]:
        """ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã‚’ãƒ†ã‚¹ãƒˆ"""
        try:
            files = {'image': ('demo.jpg', image_bytes, 'image/jpeg')}
            data = {
                'model_name': model_name,
                'text': text_prompt,
                'maintain_aspect_ratio': True,
                'return_features': False
            }
            
            response = requests.post(
                f"{self.base_url}/infer/multimodal",
                files=files,
                data=data
            )
            
            return response.json()
            
        except Exception as e:
            return {"error": str(e), "success": False}
    
    def demonstrate_capabilities(self):
        """æ©Ÿèƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("ğŸ¯ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ‡ãƒ¢")
        print("=" * 50)
        
        # 1. ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç¢ºèª
        print("1. ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç¢ºèª...")
        status = self.check_server_status()
        if "error" in status:
            print(f"âŒ ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼: {status['error']}")
            print("ğŸ’¡ ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„: python main.py")
            return
        
        print(f"âœ… ã‚µãƒ¼ãƒãƒ¼ç¨¼åƒä¸­")
        print(f"   NPUåˆ©ç”¨å¯èƒ½: {status.get('npu_available', 'Unknown')}")
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {status.get('device', 'Unknown')}")
        print()
        
        # 2. ãƒ‡ãƒ¢ç”»åƒç”Ÿæˆ
        print("2. ãƒ‡ãƒ¢ç”»åƒç”Ÿæˆ...")
        demo_image = create_demo_image()
        print("âœ… 224x224ã®ãƒ‡ãƒ¢ç”»åƒã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        print("   å†…å®¹: é’èƒŒæ™¯ã«èµ¤ã„å››è§’å½¢ã¨ã€ŒDEMOã€ãƒ†ã‚­ã‚¹ãƒˆ")
        print()
        
        # 3. æ§˜ã€…ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒ†ã‚¹ãƒˆ
        test_prompts = [
            "ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            "ã“ã®ç”»åƒã®è‰²ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
            "ã“ã®ç”»åƒã‚’è¦‹ã¦çŸ­ã„ç‰©èªã‚’ä½œã£ã¦ãã ã•ã„ã€‚",
            "ã“ã®ç”»åƒã®å¹¾ä½•å­¦çš„ãªç‰¹å¾´ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
            "ã“ã®ç”»åƒã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ãŸè©©ã‚’ä½œã£ã¦ãã ã•ã„ã€‚"
        ]
        
        print("3. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆ...")
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\n--- ãƒ†ã‚¹ãƒˆ {i} ---")
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
            
            result = self.test_multimodal_inference(demo_image, prompt)
            
            if result.get('success'):
                print("âœ… æ¨è«–æˆåŠŸ")
                print(f"å®Ÿè¡Œæ™‚é–“: {result['timing']['total_time']:.3f}ç§’")
                print(f"ãƒ‡ãƒã‚¤ã‚¹: {result.get('device', 'Unknown')}")
                
                # ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
                if 'generated_text' in result:
                    print(f"ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ: {result['generated_text']}")
                else:
                    print("Rawå‡ºåŠ›ã‚­ãƒ¼:", list(result.get('outputs', {}).keys()))
                    
            elif "Model not loaded" in str(result.get('error', '')):
                print("âš ï¸  ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                print("ğŸ’¡ å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆCLIP, BLIPç­‰ï¼‰ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
            else:
                print(f"âŒ æ¨è«–å¤±æ•—: {result.get('error', 'Unknown error')}")
        
        print("\n" + "=" * 50)
        print("ğŸ“ å®Ÿç”¨åŒ–ã®ãŸã‚ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆCLIPã€BLIPã€Flamingoç­‰ï¼‰ã‚’OpenVINOå½¢å¼ã§ç”¨æ„")
        print("2. /models/loadã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿")
        print("3. å®Ÿéš›ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œ")
        print("4. ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç”¨é€”ã«å¿œã˜ã¦å¾Œå‡¦ç†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    demo = MultimodalDemo()
    demo.demonstrate_capabilities()
    
    print("\nğŸ”§ é–‹ç™ºè€…å‘ã‘ã‚³ãƒ¼ãƒ‰ä¾‹:")
    print("""
# Python ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚³ãƒ¼ãƒ‰ä¾‹
import requests

# ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
with open('your_image.jpg', 'rb') as f:
    files = {'image': f}
    data = {
        'model_name': 'blip_model',  # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å
        'text': 'è¿™å¼ å›¾ç‰‡æè¿°äº†ä»€ä¹ˆï¼Ÿ',
        'maintain_aspect_ratio': True
    }
    response = requests.post('http://localhost:8000/infer/multimodal', 
                           files=files, data=data)
    
result = response.json()
if result['success'] and 'generated_text' in result:
    print("ç”Ÿæˆã•ã‚ŒãŸå›ç­”:", result['generated_text'])
""")

if __name__ == "__main__":
    main()